import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# PASO 5: √ÅRBOLES DE DECISI√ìN CON GRIDSEARCHCV
# ============================================================================
# Implementa:
# - Decision Tree Regressor con diferentes profundidades
# - GridSearchCV para tuning autom√°tico
# - Validaci√≥n cruzada k=5
# - Feature importance (qu√© features usa el √°rbol)
# - Comparaci√≥n con modelos de Regresi√≥n (PASO 4)
# ============================================================================

class ModeloArboles:
    """
    Clase para entrenar y evaluar √°rboles de decisi√≥n.
    """
    
    def __init__(self, X_train_path, X_test_path, y_train_path, y_test_path):
        """
        Inicializa el modelo cargando datos preprocesados.
        """
        self.X_train = pd.read_csv(X_train_path)
        self.X_test = pd.read_csv(X_test_path)
        self.y_train = pd.read_csv(y_train_path).squeeze()
        self.y_test = pd.read_csv(y_test_path).squeeze()
        
        self.modelos_entrenados = {}
        self.resultados = {}
        
        print("=" * 70)
        print("PASO 5: √ÅRBOLES DE DECISI√ìN CON GRIDSEARCHCV")
        print("=" * 70)
        print(f"\nDatos cargados:")
        print(f"  X_train: {self.X_train.shape}")
        print(f"  X_test: {self.X_test.shape}")
        print(f"  y_train: {self.y_train.shape}")
        print(f"  y_test: {self.y_test.shape}")
    
    def entrenar_decision_tree_profundo(self):
        """
        Entrena √°rbol de decisi√≥n con m√°xima profundidad (sin restricci√≥n).
        """
        print("\n" + "=" * 70)
        print("MODELO 1: DECISION TREE - SIN RESTRICCI√ìN (max_depth=None)")
        print("=" * 70)
        
        modelo = DecisionTreeRegressor(random_state=42)
        modelo.fit(self.X_train, self.y_train)
        
        # Predicciones
        y_pred_train = modelo.predict(self.X_train)
        y_pred_test = modelo.predict(self.X_test)
        
        # M√©tricas
        mse_train = mean_squared_error(self.y_train, y_pred_train)
        mse_test = mean_squared_error(self.y_test, y_pred_test)
        mae_train = mean_absolute_error(self.y_train, y_pred_train)
        mae_test = mean_absolute_error(self.y_test, y_pred_test)
        r2_train = r2_score(self.y_train, y_pred_train)
        r2_test = r2_score(self.y_test, y_pred_test)
        
        print(f"\n‚úì Modelo entrenado")
        print(f"  Profundidad del √°rbol: {modelo.get_depth()}")
        print(f"  N√∫mero de hojas: {modelo.get_n_leaves()}")
        
        print(f"\nM√âTRICAS ENTRENAMIENTO:")
        print(f"  MSE:  {mse_train:.2f}")
        print(f"  MAE:  {mae_train:.2f}")
        print(f"  R¬≤:   {r2_train:.4f}")
        
        print(f"\nM√âTRICAS PRUEBA:")
        print(f"  MSE:  {mse_test:.2f}")
        print(f"  MAE:  {mae_test:.2f}")
        print(f"  R¬≤:   {r2_test:.4f}")
        
        # Detecci√≥n de overfitting
        diferencia_r2 = r2_train - r2_test
        print(f"\n‚ö†Ô∏è  OVERFITTING:")
        print(f"  R¬≤ Train - R¬≤ Test: {diferencia_r2:.4f}")
        if diferencia_r2 > 0.15:
            print(f"  ‚Üí ALTO OVERFITTING DETECTADO ‚ùå")
        elif diferencia_r2 > 0.05:
            print(f"  ‚Üí Overfitting moderado")
        else:
            print(f"  ‚Üí Overfitting m√≠nimo ‚úì")
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'Feature': self.X_train.columns,
            'Importancia': modelo.feature_importances_
        }).sort_values('Importancia', ascending=False)
        
        print(f"\nTOP 5 FEATURES POR IMPORTANCIA:")
        print(feature_importance.head())
        
        self.modelos_entrenados['DT_Profundo'] = modelo
        self.resultados['DT_Profundo'] = {
            'mse_train': mse_train,
            'mse_test': mse_test,
            'mae_train': mae_train,
            'mae_test': mae_test,
            'r2_train': r2_train,
            'r2_test': r2_test,
            'y_pred_test': y_pred_test,
            'profundidad': modelo.get_depth(),
            'hojas': modelo.get_n_leaves(),
            'feature_importance': feature_importance
        }
        
        return self
    
    def entrenar_decision_tree_gridsearch(self):
        """
        Entrena √°rbol de decisi√≥n con GridSearchCV para tuning de profundidad.
        """
        print("\n" + "=" * 70)
        print("MODELO 2: DECISION TREE + GRIDSEARCHCV")
        print("=" * 70)
        
        # Par√°metros a probar
        param_grid = {
            'max_depth': [3, 5, 7, 10, 15, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        # GridSearchCV con validaci√≥n cruzada k=5
        dt_base = DecisionTreeRegressor(random_state=42)
        grid_search = GridSearchCV(
            dt_base,
            param_grid,
            cv=5,
            scoring='neg_mean_squared_error',
            n_jobs=-1,
            verbose=0  # Sin verbosidad para evitar spam
        )
        
        print(f"\n‚úì Ejecutando GridSearchCV con validaci√≥n cruzada k=5")
        print(f"  Combinaciones de par√°metros: 7 √ó 3 √ó 3 = 63")
        print(f"  Total de fits: 63 √ó 5 folds = 315")
        
        grid_search.fit(self.X_train, self.y_train)
        
        print(f"\n‚úì GridSearchCV completado")
        print(f"\nMEJORES PAR√ÅMETROS ENCONTRADOS:")
        print(f"  max_depth: {grid_search.best_params_['max_depth']}")
        print(f"  min_samples_split: {grid_search.best_params_['min_samples_split']}")
        print(f"  min_samples_leaf: {grid_search.best_params_['min_samples_leaf']}")
        print(f"  MSE en validaci√≥n cruzada: {-grid_search.best_score_:.2f}")
        
        # Usar mejor modelo
        mejor_modelo = grid_search.best_estimator_
        
        # Predicciones
        y_pred_train = mejor_modelo.predict(self.X_train)
        y_pred_test = mejor_modelo.predict(self.X_test)
        
        # M√©tricas
        mse_train = mean_squared_error(self.y_train, y_pred_train)
        mse_test = mean_squared_error(self.y_test, y_pred_test)
        mae_train = mean_absolute_error(self.y_train, y_pred_train)
        mae_test = mean_absolute_error(self.y_test, y_pred_test)
        r2_train = r2_score(self.y_train, y_pred_train)
        r2_test = r2_score(self.y_test, y_pred_test)
        
        print(f"\nM√âTRICAS ENTRENAMIENTO:")
        print(f"  MSE:  {mse_train:.2f}")
        print(f"  MAE:  {mae_train:.2f}")
        print(f"  R¬≤:   {r2_train:.4f}")
        
        print(f"\nM√âTRICAS PRUEBA:")
        print(f"  MSE:  {mse_test:.2f}")
        print(f"  MAE:  {mae_test:.2f}")
        print(f"  R¬≤:   {r2_test:.4f}")
        
        diferencia_r2 = r2_train - r2_test
        print(f"\n‚ö†Ô∏è  OVERFITTING:")
        print(f"  R¬≤ Train - R¬≤ Test: {diferencia_r2:.4f}")
        if diferencia_r2 > 0.15:
            print(f"  ‚Üí ALTO OVERFITTING DETECTADO ‚ùå")
        elif diferencia_r2 > 0.05:
            print(f"  ‚Üí Overfitting moderado")
        else:
            print(f"  ‚Üí Overfitting m√≠nimo ‚úì")
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'Feature': self.X_train.columns,
            'Importancia': mejor_modelo.feature_importances_
        }).sort_values('Importancia', ascending=False)
        
        print(f"\nTOP 5 FEATURES POR IMPORTANCIA:")
        print(feature_importance.head())
        
        self.modelos_entrenados['DT_GridSearchCV'] = mejor_modelo
        self.resultados['DT_GridSearchCV'] = {
            'mse_train': mse_train,
            'mse_test': mse_test,
            'mae_train': mae_train,
            'mae_test': mae_test,
            'r2_train': r2_train,
            'r2_test': r2_test,
            'y_pred_test': y_pred_test,
            'profundidad': mejor_modelo.get_depth(),
            'hojas': mejor_modelo.get_n_leaves(),
            'feature_importance': feature_importance,
            'best_params': grid_search.best_params_
        }
        
        return self
    
    def generar_tabla_comparativa(self):
        """
        Genera tabla comparativa de todos los modelos de √°rboles.
        """
        print("\n" + "=" * 70)
        print("TABLA COMPARATIVA DE √ÅRBOLES")
        print("=" * 70)
        
        tabla = []
        for nombre_modelo, metricas in self.resultados.items():
            tabla.append({
                'Modelo': nombre_modelo,
                'Profundidad': metricas['profundidad'],
                'Hojas': metricas['hojas'],
                'MSE_Train': f"{metricas['mse_train']:.2f}",
                'MSE_Test': f"{metricas['mse_test']:.2f}",
                'MAE_Train': f"{metricas['mae_train']:.2f}",
                'MAE_Test': f"{metricas['mae_test']:.2f}",
                'R¬≤_Train': f"{metricas['r2_train']:.4f}",
                'R¬≤_Test': f"{metricas['r2_test']:.4f}"
            })
        
        df_tabla = pd.DataFrame(tabla)
        print("\n" + df_tabla.to_string(index=False))
        
        # Guardar tabla
        df_tabla.to_csv('resultados_arboles.csv', index=False)
        print("\n‚úì Tabla guardada en: resultados_arboles.csv")
        
        return self
    
    def generar_graficas_predicciones(self):
        """
        Genera gr√°ficas de predicciones vs realidad para cada √°rbol.
        """
        print("\n" + "=" * 70)
        print("GENERANDO GR√ÅFICAS DE PREDICCIONES")
        print("=" * 70)
        
        import matplotlib
        matplotlib.use('Agg')
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        colores = {'DT_Profundo': '#FF6B6B', 'DT_GridSearchCV': '#4ECDC4'}
        
        for idx, (nombre_modelo, metricas) in enumerate(self.resultados.items()):
            ax = axes[idx]
            
            y_pred = metricas['y_pred_test']
            
            # Scatter plot: Real vs Predicho
            ax.scatter(self.y_test, y_pred, alpha=0.6, s=100, 
                      color=colores[nombre_modelo], edgecolors='black', linewidth=0.5)
            
            # L√≠nea diagonal (predicci√≥n perfecta)
            min_val = min(self.y_test.min(), y_pred.min())
            max_val = max(self.y_test.max(), y_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Predicci√≥n Perfecta')
            
            ax.set_xlabel('Valores Reales', fontsize=11, fontweight='bold')
            ax.set_ylabel('Valores Predichos', fontsize=11, fontweight='bold')
            ax.set_title(f'{nombre_modelo}\nR¬≤={metricas["r2_test"]:.4f}, MAE={metricas["mae_test"]:.2f}', 
                        fontsize=12, fontweight='bold')
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('01_arboles_predicciones_vs_real.png', dpi=300, bbox_inches='tight')
        plt.close(fig)
        print("‚úì Guardado: 01_arboles_predicciones_vs_real.png")
        
        return self
    
    def generar_graficas_feature_importance(self):
        """
        Genera gr√°ficas de importancia de features para cada √°rbol.
        """
        print("‚úì Generando gr√°ficas de feature importance...")
        
        import matplotlib
        matplotlib.use('Agg')
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        colores_bar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#F7B731', '#5F27CD']
        
        for idx, (nombre_modelo, metricas) in enumerate(self.resultados.items()):
            ax = axes[idx]
            
            feature_imp = metricas['feature_importance'].head(10)
            
            bars = ax.barh(feature_imp['Feature'], feature_imp['Importancia'],
                           color=colores_bar, edgecolor='black', alpha=0.8, linewidth=1)
            
            ax.set_xlabel('Importancia', fontsize=11, fontweight='bold')
            ax.set_title(f'{nombre_modelo}\nTop 10 Features (Profundidad={metricas["profundidad"]})', 
                        fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3, axis='x')
            
            # Anotar valores en barras
            for bar in bars:
                width = bar.get_width()
                ax.text(width, bar.get_y() + bar.get_height()/2.,
                       f'{width:.3f}', ha='left', va='center', fontsize=9, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('02_arboles_feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close(fig)
        print("‚úì Guardado: 02_arboles_feature_importance.png")
        
        return self
    
    def generar_graficas_residuos(self):
        """
        Genera gr√°ficas de residuos para diagn√≥stico.
        """
        print("‚úì Generando gr√°ficas de residuos...")
        
        import matplotlib
        matplotlib.use('Agg')
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        colores = {'DT_Profundo': '#FF6B6B', 'DT_GridSearchCV': '#4ECDC4'}
        
        for idx, (nombre_modelo, metricas) in enumerate(self.resultados.items()):
            ax = axes[idx]
            
            y_pred = metricas['y_pred_test']
            residuos = self.y_test - y_pred
            
            # Scatter: Residuos vs Predicciones
            ax.scatter(y_pred, residuos, alpha=0.6, s=100,
                      color=colores[nombre_modelo], edgecolors='black', linewidth=0.5)
            ax.axhline(y=0, color='r', linestyle='--', linewidth=2)
            
            ax.set_xlabel('Valores Predichos', fontsize=11, fontweight='bold')
            ax.set_ylabel('Residuos', fontsize=11, fontweight='bold')
            ax.set_title(f'{nombre_modelo}\nRes√≠duos vs Predicciones', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('03_arboles_residuos.png', dpi=300, bbox_inches='tight')
        plt.close(fig)
        print("‚úì Guardado: 03_arboles_residuos.png")
        
        return self
    
    def generar_comparativa_con_regresion(self):
        """
        Compara resultados de √°rboles vs regresi√≥n (PASO 4).
        """
        print("\n" + "=" * 70)
        print("COMPARACI√ìN √ÅRBOLES vs REGRESI√ìN (PASO 4)")
        print("=" * 70)
        
        # Cargar resultados de regresi√≥n
        try:
            df_regresion = pd.read_csv('resultados_regresion.csv')
            
            print("\nRESULTADOS REGRESI√ìN (PASO 4):")
            print(df_regresion.to_string(index=False))
            
            print("\nRESULTADOS √ÅRBOLES (PASO 5):")
            df_arboles = pd.read_csv('resultados_arboles.csv')
            print(df_arboles.to_string(index=False))
            
            # An√°lisis comparativo
            print("\n" + "=" * 70)
            print("AN√ÅLISIS COMPARATIVO")
            print("=" * 70)
            
            r2_ridge = 0.9775  # Del PASO 4
            r2_mejor_arbol = float(df_arboles.iloc[df_arboles['R¬≤_Test'].astype(float).argmax()]['R¬≤_Test'])
            
            print(f"\nMejor R¬≤ Regresi√≥n (Ridge): 0.9775")
            print(f"Mejor R¬≤ √Årboles: {r2_mejor_arbol:.4f}")
            
            if r2_mejor_arbol > r2_ridge:
                print(f"‚úÖ √ÅRBOLES GANAN por {(r2_mejor_arbol - r2_ridge)*100:.2f}%")
            elif r2_mejor_arbol < r2_ridge:
                print(f"‚ùå REGRESI√ìN GANA por {(r2_ridge - r2_mejor_arbol)*100:.2f}%")
            else:
                print(f"‚öñÔ∏è  EMPATE en rendimiento")
        
        except FileNotFoundError:
            print("\n‚ö†Ô∏è  No se encontr√≥ archivo resultados_regresion.csv")
            print("  (Aseg√∫rate de haber ejecutado PASO 4 primero)")
        
        return self
    
    def generar_reporte_final(self):
        """
        Genera reporte final con conclusiones.
        """
        print("\n" + "=" * 70)
        print("GENERANDO REPORTE FINAL")
        print("=" * 70)
        
        # Encontrar mejor modelo
        mejor_modelo_arbol = max(self.resultados.items(), 
                                 key=lambda x: x[1]['r2_test'])
        
        reporte = f"""
REPORTE FINAL - √ÅRBOLES DE DECISI√ìN
DENGUE COLOMBIA 2022-2024
{'=' * 70}

1. RESUMEN EJECUTIVO
   - Objetivo: Predecir casos de dengue por semana usando √°rboles
   - Modelos: Decision Tree sin restricci√≥n + Decision Tree con GridSearchCV
   - M√©todo de tuning: GridSearchCV con validaci√≥n cruzada k=5
   - Muestras entrenamiento: 121
   - Muestras prueba: 31

2. RESULTADOS POR MODELO

   DECISION TREE - SIN RESTRICCI√ìN:
   - Profundidad: {self.resultados['DT_Profundo']['profundidad']}
   - N√∫mero de hojas: {self.resultados['DT_Profundo']['hojas']}
   - R¬≤ Train: {self.resultados['DT_Profundo']['r2_train']:.4f}
   - R¬≤ Test:  {self.resultados['DT_Profundo']['r2_test']:.4f}
   - MSE Test: {self.resultados['DT_Profundo']['mse_test']:.2f}
   - MAE Test: {self.resultados['DT_Profundo']['mae_test']:.2f}
   
   DECISION TREE + GRIDSEARCHCV:
   - Profundidad: {self.resultados['DT_GridSearchCV']['profundidad']}
   - N√∫mero de hojas: {self.resultados['DT_GridSearchCV']['hojas']}
   - R¬≤ Train: {self.resultados['DT_GridSearchCV']['r2_train']:.4f}
   - R¬≤ Test:  {self.resultados['DT_GridSearchCV']['r2_test']:.4f}
   - MSE Test: {self.resultados['DT_GridSearchCV']['mse_test']:.2f}
   - MAE Test: {self.resultados['DT_GridSearchCV']['mae_test']:.2f}

3. MEJOR MODELO
   Modelo: {mejor_modelo_arbol[0]}
   R¬≤ Test: {mejor_modelo_arbol[1]['r2_test']:.4f}
   MAE Test: {mejor_modelo_arbol[1]['mae_test']:.2f}

4. AN√ÅLISIS DE OVERFITTING
   
   Decision Tree (Sin restricci√≥n):
   - Diferencia R¬≤: {self.resultados['DT_Profundo']['r2_train'] - self.resultados['DT_Profundo']['r2_test']:.4f}
   - Interpretaci√≥n: {'ALTO OVERFITTING' if (self.resultados['DT_Profundo']['r2_train'] - self.resultados['DT_Profundo']['r2_test']) > 0.15 else 'Overfitting moderado' if (self.resultados['DT_Profundo']['r2_train'] - self.resultados['DT_Profundo']['r2_test']) > 0.05 else 'Overfitting m√≠nimo'}
   
   Decision Tree (GridSearchCV):
   - Diferencia R¬≤: {self.resultados['DT_GridSearchCV']['r2_train'] - self.resultados['DT_GridSearchCV']['r2_test']:.4f}
   - Interpretaci√≥n: {'ALTO OVERFITTING' if (self.resultados['DT_GridSearchCV']['r2_train'] - self.resultados['DT_GridSearchCV']['r2_test']) > 0.15 else 'Overfitting moderado' if (self.resultados['DT_GridSearchCV']['r2_train'] - self.resultados['DT_GridSearchCV']['r2_test']) > 0.05 else 'Overfitting m√≠nimo'}

5. FEATURE IMPORTANCE
   
   Top 3 Features m√°s importantes:
   {self.resultados['DT_GridSearchCV']['feature_importance'].head(3).to_string()}

6. CONCLUSIONES
   - √Årboles vs Regresi√≥n: Comparar R¬≤ test (~0.975 esperado en regresi√≥n)
   - GridSearchCV mejor√≥ la regularizaci√≥n autom√°ticamente
   - Features lag siguen siendo importantes para √°rboles
   - Profundidad √≥ptima: {self.resultados['DT_GridSearchCV']['profundidad']} (m√°s somero que sin restricci√≥n)

7. RECOMENDACIONES PARA PR√ìXIMOS PASOS
   - PASO 6: Probar Random Forest (m√∫ltiples √°rboles = mejor generalizaci√≥n)
   - PASO 7: Redes Neuronales pueden capturar interacciones complejas
   - Considerar ensambles (votaci√≥n entre modelos)

ARCHIVOS GENERADOS:
- resultados_arboles.csv: Tabla comparativa de modelos
- 01_arboles_predicciones_vs_real.png: Scatter plots predicciones
- 02_arboles_feature_importance.png: Importancia de features
- 03_arboles_residuos.png: An√°lisis de residuos

{'=' * 70}
        """
        
        print(reporte)
        
        with open('reporte_arboles.txt', 'w', encoding='utf-8') as f:
            f.write(reporte)
        
        print("\n‚úì Reporte guardado: reporte_arboles.txt")


# ============================================================================
# EJECUCI√ìN PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    # Cargar datos (usando datos normalizados como antes)
    modelo = ModeloArboles(
        'X_train_normalizado.csv',
        'X_test_normalizado.csv',
        'y_train.csv',
        'y_test.csv'
    )
    
    # Entrenar modelos
    (modelo
     .entrenar_decision_tree_profundo()
     .entrenar_decision_tree_gridsearch()
     .generar_tabla_comparativa()
     .generar_graficas_predicciones()
     .generar_graficas_feature_importance()
     .generar_graficas_residuos()
     .generar_comparativa_con_regresion()
     .generar_reporte_final())
    
    print("\n" + "=" * 70)
    print("‚úì PASO 5 COMPLETADO EXITOSAMENTE")
    print("=" * 70)
    print("\nModelos entrenados y evaluados:")
    print("  1. Decision Tree (sin restricci√≥n)")
    print("  2. Decision Tree (con GridSearchCV)")
    print("\nArchivos generados:")
    print("  - resultados_arboles.csv")
    print("  - 01_arboles_predicciones_vs_real.png")
    print("  - 02_arboles_feature_importance.png")
    print("  - 03_arboles_residuos.png")
    print("  - reporte_arboles.txt")
    print("\nüöÄ Pr√≥ximo paso: PASO 6 - Random Forest")
